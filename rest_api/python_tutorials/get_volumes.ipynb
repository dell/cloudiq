{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import time # for some performance testing\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CloudIQ REST API endpoints\n",
    "CIQ_TOKEN_URL = 'https://cloudiq.apis.dell.com/auth/oauth/v2/token'\n",
    "CIQ_BASE_API_URL = 'https://cloudiq.apis.dell.com/cloudiq/rest/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877baf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't want your API credentials to leak, do you?\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "\n",
    "print('OAuth2 Client Credentials ID used:', client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4edd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication to CloudIQ REST API\n",
    "client = BackendApplicationClient(client_id=client_id)\n",
    "oauth = OAuth2Session(client=client)\n",
    "token = oauth.fetch_token(token_url=CIQ_TOKEN_URL, client_id=client_id, client_secret=client_secret)\n",
    "\n",
    "print('OAuth2 Token type:', token['token_type'], '- Expires in:', token['expires_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69911810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all volumes / LUNs\n",
    "params = { \n",
    "#     'filter': \"system_type eq 'POWERSTORE'\",\n",
    "    'select': 'object_name,system,system_type,allocated_size,total_size,tags,system_tags'\n",
    "}\n",
    "\n",
    "r = oauth.get(CIQ_BASE_API_URL + 'volumes', params=params)\n",
    "print('Status Code:', r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many instances?\n",
    "print('Number of instances:', r.json()['paging']['total_instances'])\n",
    "# r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame\n",
    "df_object = pd.json_normalize(r.json(), record_path =['results'])\n",
    "\n",
    "print('Dataframe size:', df_object.shape)\n",
    "# df_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data\n",
    "df_object.dropna(inplace=True) #, subset=['allocated_size'])\n",
    "print('Dataframe size:', df_object.shape)\n",
    "\n",
    "# Protecting the innocent\n",
    "def md5hash(s):\n",
    "    s = str(s)\n",
    "    return hashlib.md5(s.encode('utf-8')).hexdigest()\n",
    "\n",
    "df_object['object_name_hash'] = df_object['object_name'].apply(md5hash)\n",
    "# An obfuscated object name, in case real names should not be displayed\n",
    "df_object['o_object_name'] = df_object['object_name_hash'].apply(lambda x: x[:4] + x[-4:])\n",
    "df_object['used_pct'] = (df_object['allocated_size'] / df_object['total_size']) * 100\n",
    "df_object['used_pct'] = df_object['used_pct'].round(2)\n",
    "df_object['total_size_gb'] = df_object['total_size'].apply(lambda x: x/(1000**3))\n",
    "df_object['total_size_gb'] = df_object['total_size_gb'].round(2)\n",
    "df_object['allocated_size_gb'] = df_object['allocated_size'].apply(lambda x: x/(1000**3))\n",
    "df_object['allocated_size_gb'] = df_object['allocated_size_gb'].round(2)\n",
    "\n",
    "print('Dataframe size:', df_object.shape)\n",
    "# df_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate per BU and per project - those are CloudIQ custom tags defined at the volume level\n",
    "# Compute KPIs\n",
    "by_bu = df_object.groupby('tags.business_unit')\n",
    "by_project = df_object.groupby('tags.project')\n",
    "\n",
    "df_aggregates_by_bu = by_bu.agg(\n",
    "    total_size=pd.NamedAgg(column='total_size_gb', aggfunc='sum'),\n",
    "    used_size=pd.NamedAgg(column='allocated_size_gb', aggfunc='sum'),\n",
    "    count_object=pd.NamedAgg(column='object_name', aggfunc='count'),\n",
    ").reset_index()\n",
    "\n",
    "df_aggregates_by_project = by_project.agg(\n",
    "    total_size=pd.NamedAgg(column='total_size_gb', aggfunc='sum'),\n",
    "    used_size=pd.NamedAgg(column='allocated_size_gb', aggfunc='sum'),\n",
    "    count_object=pd.NamedAgg(column='object_name', aggfunc='count'),\n",
    ").reset_index()\n",
    "\n",
    "print('BU Dataframe size:', df_aggregates_by_bu.shape)\n",
    "print('Project Dataframe size:', df_aggregates_by_project.shape)\n",
    "print(df_aggregates_by_bu)\n",
    "print(df_aggregates_by_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching some metrics - functions\n",
    "MAX_ID = 5 # Not all resource ids at the same time, but in chunks\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "# Transforming the metrics data into a DataFrame\n",
    "def flatten(s):\n",
    "    metrics = s['metrics']\n",
    "    results = s['results']\n",
    "    \n",
    "    # Creating a record per object, per metric and per timestamp to then create a DataFrame\n",
    "    data = [{'object': metric['id'], 'datetime': ts['timestamp']} | dict(zip(metrics, ts['values']))\n",
    "            for metric in results\n",
    "            for ts in metric['timestamps']]\n",
    "    \n",
    "    df = pd.DataFrame.from_records(data)\n",
    "    if not df.empty:\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Crafting the POST query\n",
    "def post_metric_json(from_dt, to_dt, ids, resource, metrics, interval):\n",
    "    return {\n",
    "        'from': from_dt.isoformat(),\n",
    "        'to': to_dt.isoformat(),\n",
    "        'resource_type': resource,\n",
    "        'ids': ids,\n",
    "        'interval': interval,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "def get_metrics_df(from_dt, to_dt, ids, resource, metrics, interval):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    with tqdm(total=len(ids)) as pbar:\n",
    "        # Split the request into sub-requests (resource ids)\n",
    "        for ids_subset in chunks(ids, MAX_ID):\n",
    "            from_dt_post = from_dt\n",
    "            to_dt_post = to_dt\n",
    "            \n",
    "            # Send requests until we have all content - i.e. until no more HTTP 206 / Partial Content\n",
    "            nb_request = 0\n",
    "            while True:\n",
    "                json_to_post = post_metric_json(from_dt_post, to_dt_post, ids_subset, resource, metrics, interval)\n",
    "                nb_request += 1\n",
    "\n",
    "                r = oauth.post(CIQ_BASE_API_URL + 'metrics/query', json=json_to_post)\n",
    "                if r.status_code == 200:\n",
    "                    new_data = flatten(r.json())\n",
    "                    data = pd.concat([data, new_data])\n",
    "                    break\n",
    "                elif r.status_code == 206:\n",
    "                    new_data = flatten(r.json())\n",
    "                    data = pd.concat([data, new_data])\n",
    "                    if not new_data.empty:\n",
    "                        from_dt_post = max(new_data['datetime'])\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            # print('Number of API calls:', nb_request)\n",
    "            print('Updated dataframe size:', data.shape)\n",
    "            pbar.update(len(ids_subset))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45461b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching some metrics\n",
    "TO = datetime.now(timezone.utc).replace(microsecond=0)\n",
    "FROM = TO - timedelta(days=90)\n",
    "print('From:', FROM)\n",
    "print('To:', TO)\n",
    "\n",
    "MAX_ID = 5\n",
    "\n",
    "RESOURCE = 'volume'\n",
    "\n",
    "METRICS = [\n",
    "        'used_size',\n",
    "        'free_size',\n",
    "        'total_size',\n",
    "        'iops',\n",
    "        'bandwidth'\n",
    "]\n",
    "\n",
    "INTERVAL = 'PT1H'\n",
    "\n",
    "OBJECTS = df_object['id'].tolist()\n",
    "\n",
    "start = time.time()\n",
    "df_all_metrics_data = get_metrics_df(FROM, TO, OBJECTS, RESOURCE, METRICS, INTERVAL)\n",
    "end = time.time()\n",
    "\n",
    "print('Dataframe size:', df_all_metrics_data.shape)\n",
    "print('Time (ms):', (end-start)*1000)\n",
    "# df_all_metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming in right scale\n",
    "# df_all_metrics_data['total_size_gb'] = df_all_metrics_data['total_size'].apply(lambda x: x/(1000**3))\n",
    "# df_all_metrics_data['total_size_gb'] = df_all_metrics_data['total_size_gb'].round(2)\n",
    "# df_all_metrics_data['used_size_gb'] = df_all_metrics_data['used_size'].apply(lambda x: x/(1000**3))\n",
    "# df_all_metrics_data['used_size_gb'] = df_all_metrics_data['used_size_gb'].round(2)\n",
    "\n",
    "# Merge with metadata\n",
    "df_all_metrics_data = pd.merge(df_all_metrics_data, df_object[['tags.business_unit', 'tags.project', 'id', 'object_name', 'o_object_name']], how='left', left_on='object', right_on='id')\n",
    "df_all_metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute KPIs\n",
    "by_object = df_all_metrics_data.groupby('object')\n",
    "\n",
    "def p95(x):\n",
    "    return x.quantile(0.95)\n",
    "\n",
    "df_aggregates_by_object = by_object.agg(\n",
    "    min_iops=pd.NamedAgg(column='iops', aggfunc='min'),\n",
    "    max_iops=pd.NamedAgg(column='iops', aggfunc='max'),\n",
    "    avg_iops=pd.NamedAgg(column='iops', aggfunc='mean'),\n",
    "    median_iops=pd.NamedAgg(column='iops', aggfunc='median'),\n",
    "    count_iops=pd.NamedAgg(column='iops', aggfunc='count'),\n",
    "    p95_iops=pd.NamedAgg(column='iops', aggfunc=p95),\n",
    ").reset_index()\n",
    "\n",
    "df_aggregates_by_object['p95_iops'] = df_aggregates_by_object['p95_iops'].round(2)\n",
    "df_aggregates_by_object['avg_iops'] = df_aggregates_by_object['avg_iops'].round(2)\n",
    "df_aggregates_by_object['median_iops'] = df_aggregates_by_object['median_iops'].round(2)\n",
    "\n",
    "print('Dataframe size:', df_aggregates_by_object.shape)\n",
    "# df_aggregates_by_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cbfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge attribute level and KPI level datasets\n",
    "df_all_object = pd.merge(df_object, df_aggregates_by_object, how='left', left_on='id', right_on='object')\n",
    "\n",
    "print('Dataframe size:', df_all_object.shape)\n",
    "# df_all_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2abfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default treemap on \"used_pct\"\n",
    "fig = px.treemap(df_all_object, path=[px.Constant(\"ALL\"), 'tags.business_unit', 'tags.project', 'o_object_name'], \n",
    "                 values='total_size_gb',\n",
    "                 color='used_pct',\n",
    "                 custom_data=df_object[['tags.business_unit', 'tags.project', 'o_object_name']],\n",
    "                 hover_data=['id'],\n",
    "                 color_continuous_scale='Jet')\n",
    "\n",
    "fig.update_traces(root_color='lightgrey', hovertemplate='Volume: %{label}<br>Used capacity: %{color} %<br>Used capacity: %{value} GB<extra></extra><br><br>Project: %{customdata[0]} / %{customdata[1]}')\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the metric over time\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "        hovertemplate='Volume: %{y}<br>Date: %{x}<br>Value: %{z} IOPS<extra></extra><br><br>Project: %{customdata[0]} / %{customdata[1]}',\n",
    "        z=df_all_metrics_data['iops'],\n",
    "        x=df_all_metrics_data['datetime'],\n",
    "        y=df_all_metrics_data['o_object_name'],\n",
    "        customdata=df_all_metrics_data[['tags.business_unit', 'tags.project']],\n",
    "        colorscale='RdBu_r')) # RdBu_r OR Jet\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Value over time',\n",
    "    xaxis_nticks=24,\n",
    "    height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to play with the Figure's layout and data\n",
    "# print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun: buttons to switch metrics and chart type\n",
    "cols = ['used_pct', 'max_iops', 'median_iops', 'p95_iops']\n",
    "\n",
    "fig = go.Figure()\n",
    "for col in cols:\n",
    "    figpx = px.treemap(df_all_object.assign(Plot=col), \n",
    "                       path=[px.Constant(\"ALL\"), 'tags.business_unit', 'tags.project', 'o_object_name'],\n",
    "                       values='total_size_gb',\n",
    "                       color=col,\n",
    "                       hover_data=['Plot'],\n",
    "                       color_continuous_scale='Jet').update_traces(visible=False)\n",
    "    \n",
    "    fig.add_traces(figpx.data)\n",
    "    \n",
    "fig.update_layout({\n",
    "    'coloraxis': {\n",
    "        'colorbar': {'title': {'text': 'Value'}},\n",
    "        'colorscale': [[0.0, 'rgb(0,0,131)'], \n",
    "                       [0.2, 'rgb(0,60,170)'], \n",
    "                       [0.4, 'rgb(5,255,255)'], \n",
    "                       [0.6, 'rgb(255,255,0)'],\n",
    "                       [0.8, 'rgb(250,0,0)'],\n",
    "                       [1.0, 'rgb(128,0,0)']]\n",
    "    },\n",
    "    'legend': {'tracegroupgap': 0},\n",
    "    'margin': {'b': 25, 'l': 25, 'r': 25, 't': 50}\n",
    "})\n",
    "    \n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": \n",
    "            [\n",
    "                {\n",
    "                    \"label\": k,\n",
    "                    \"method\": \"update\",\n",
    "                    \"args\": \n",
    "                    [\n",
    "                        {\"visible\": [t.customdata[0][0]==k for t in fig.data]},\n",
    "                    ],\n",
    "                }\n",
    "                for k in cols\n",
    "            ],\n",
    "            'x': 0.27,\n",
    "            'y': 1.1\n",
    "        },\n",
    "        dict(\n",
    "            buttons = list(\n",
    "            [\n",
    "                dict(\n",
    "                    args=[\"type\", 'treemap'],\n",
    "                    label=\"Treemap\",\n",
    "                    method=\"restyle\"\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[\"type\", 'sunburst'],\n",
    "                    label=\"Sunburst\",\n",
    "                    method=\"restyle\"\n",
    "                )\n",
    "            ]),\n",
    "            type = \"buttons\",\n",
    "            direction=\"right\",\n",
    "            pad={\"r\": 10, \"t\": 10},\n",
    "            showactive=True,\n",
    "            x=0.55,\n",
    "            xanchor=\"left\",\n",
    "            y=1.125,\n",
    "            yanchor=\"top\"\n",
    "        )\n",
    "    ]\n",
    ").update_traces(visible=True, selector=lambda t: t.customdata[0][0]==cols[0])\n",
    "\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(text=\"Color's value:\", x=0, xref=\"paper\", y=1.08, yref=\"paper\",\n",
    "                             align=\"left\", showarrow=False),\n",
    "        dict(text=\"Chart style:\", x=0.5, xref=\"paper\", y=1.08,\n",
    "                             yref=\"paper\", showarrow=False),\n",
    "    ])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e60bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart over time for time series / metric\n",
    "fig = px.line(df_all_metrics_data, color='o_object_name', x='datetime', y=['iops'], \n",
    "        title='IOPS over time')\n",
    "fig.update_xaxes(rangeslider_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d5cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
